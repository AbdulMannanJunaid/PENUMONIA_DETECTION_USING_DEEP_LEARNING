{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1NeAEHX-4gOVsTnBVNUesUsp7EWL2oO5x","authorship_tag":"ABX9TyMNKy9MZZgP0+sHajUMcNJR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"bvxuBa9trA3H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","\n","# Constants\n","SAMPLE_RATE = 22050  # Adjust the sample rate as needed\n","DURATION = 4  # Adjust the duration as needed\n","MFCC_FEATURES = 13  # Adjust the number of MFCC features as needed\n","\n","# Paths to the audio data directories\n","pneumonia_audio_dir = '/content/drive/MyDrive/New Audio Folder/Pneumonia'\n","normal_audio_dir = '/content/drive/MyDrive/New Audio Folder/Normal'\n","\n","# Function to extract MFCC features\n","def extract_features(file_path):\n","    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n","    mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=MFCC_FEATURES)\n","\n","    # Pad or truncate to a fixed length (e.g., 173, or any desired length)\n","    target_length = 173  # You can adjust this value\n","    if mfccs.shape[1] < target_length:\n","        mfccs = np.pad(mfccs, ((0, 0), (0, target_length - mfccs.shape[1])), mode='constant')\n","    elif mfccs.shape[1] > target_length:\n","        mfccs = mfccs[:, :target_length]\n","\n","    return mfccs\n","\n","# Feature extraction for Pneumonia audio\n","pneumonia_features = []\n","for filename in os.listdir(pneumonia_audio_dir):\n","    if filename.endswith('.wav'):\n","        file_path = os.path.join(pneumonia_audio_dir, filename)\n","        mfccs = extract_features(file_path)\n","        pneumonia_features.append(mfccs)\n","\n","# Feature extraction for Normal audio\n","normal_features = []\n","for filename in os.listdir(normal_audio_dir):\n","    if filename.endswith('.wav'):\n","        file_path = os.path.join(normal_audio_dir, filename)\n","        mfccs = extract_features(file_path)\n","        normal_features.append(mfccs)\n","\n","# Save the extracted features as NumPy arrays\n","np.save('/content/drive/MyDrive/Features/Pneumonia_Features.npy', np.array(pneumonia_features))\n","np.save('/content/drive/MyDrive/Features/Normal_Features.npy', np.array(normal_features))\n"],"metadata":{"id":"qtmaSD8yr6ZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","from sklearn.model_selection import train_test_split\n","\n","# Define the paths to your audio data directories\n","pneumonia_dir = '/content/drive/MyDrive/New Audio Folder/Pneumonia'\n","normal_dir = '/content/drive/MyDrive/New Audio Folder/Normal'\n","\n","# List the audio files in each directory\n","pneumonia_files = [os.path.join(pneumonia_dir, filename) for filename in os.listdir(pneumonia_dir) if filename.endswith('.wav')]\n","normal_files = [os.path.join(normal_dir, filename) for filename in os.listdir(normal_dir) if filename.endswith('.wav')]\n","\n","# Shuffle the data\n","random.shuffle(pneumonia_files)\n","random.shuffle(normal_files)\n","\n","# Define split ratios (e.g., 80% training, 10% validation, 10% test)\n","train_ratio = 0.8\n","val_ratio = 0.1\n","\n","# Split the data into training, validation, and test sets\n","pneumonia_train, pneumonia_test = train_test_split(pneumonia_files, test_size=(1 - train_ratio))\n","pneumonia_val, pneumonia_test = train_test_split(pneumonia_test, test_size=(val_ratio / (1 - train_ratio)))\n","\n","normal_train, normal_test = train_test_split(normal_files, test_size=(1 - train_ratio))\n","normal_val, normal_test = train_test_split(normal_test, test_size=(val_ratio / (1 - train_ratio)))\n","\n","# Combine data from both classes\n","train_data = pneumonia_train + normal_train\n","val_data = pneumonia_val + normal_val\n","test_data = pneumonia_test + normal_test\n"],"metadata":{"id":"BS6f4HKKxsgG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**CNN Model**"],"metadata":{"id":"iXD4VZJ3yaKc"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Define your CNN model\n","target_length = 173  # Replace with the actual maximum MFCC feature length\n","NUM_CLASSES = 2  # Define the number of classes in your dataset (Normal and Pneumonia)\n","\n","input_shape = (MFCC_FEATURES, target_length, 1)\n","model = keras.Sequential([\n","    # Convolutional layers\n","    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n","    keras.layers.MaxPooling2D((2, 2)),\n","    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    keras.layers.MaxPooling2D((2, 2)),\n","\n","    # Flatten and Dense layers\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary to see the architecture\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2D0U-lFyBC5","executionInfo":{"status":"ok","timestamp":1697784128985,"user_tz":-330,"elapsed":919,"user":{"displayName":"Mannan Junaid Abdul","userId":"12242438375363016538"}},"outputId":"2d80dd8e-021d-4ad4-b8bb-4506bb276c8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 13, 173, 32)       320       \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 6, 86, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 6, 86, 64)         18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 3, 43, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_2 (Flatten)         (None, 8256)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               1056896   \n","                                                                 \n"," dense_4 (Dense)             (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 1075970 (4.10 MB)\n","Trainable params: 1075970 (4.10 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_N1MzC2z1ZQ","executionInfo":{"status":"ok","timestamp":1697784159987,"user_tz":-330,"elapsed":23468,"user":{"displayName":"Mannan Junaid Abdul","userId":"12242438375363016538"}},"outputId":"f44399a1-2119-4a52-e797-4a3a08c2d276"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","16/16 [==============================] - 3s 112ms/step - loss: 12.4458 - accuracy: 0.5351 - val_loss: 0.9166 - val_accuracy: 0.5865\n","Epoch 2/10\n","16/16 [==============================] - 2s 103ms/step - loss: 0.6345 - accuracy: 0.6570 - val_loss: 0.6026 - val_accuracy: 0.6923\n","Epoch 3/10\n","16/16 [==============================] - 2s 99ms/step - loss: 0.4923 - accuracy: 0.7665 - val_loss: 0.5521 - val_accuracy: 0.6827\n","Epoch 4/10\n","16/16 [==============================] - 2s 99ms/step - loss: 0.3312 - accuracy: 0.8822 - val_loss: 0.4543 - val_accuracy: 0.7981\n","Epoch 5/10\n","16/16 [==============================] - 2s 105ms/step - loss: 0.1896 - accuracy: 0.9421 - val_loss: 0.3145 - val_accuracy: 0.8558\n","Epoch 6/10\n","16/16 [==============================] - 2s 147ms/step - loss: 0.1180 - accuracy: 0.9731 - val_loss: 0.2287 - val_accuracy: 0.8942\n","Epoch 7/10\n","16/16 [==============================] - 3s 209ms/step - loss: 0.0676 - accuracy: 0.9855 - val_loss: 0.1782 - val_accuracy: 0.9327\n","Epoch 8/10\n","16/16 [==============================] - 3s 215ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 0.1519 - val_accuracy: 0.8942\n","Epoch 9/10\n","16/16 [==============================] - 3s 215ms/step - loss: 0.0280 - accuracy: 0.9959 - val_loss: 0.1489 - val_accuracy: 0.9423\n","Epoch 10/10\n","16/16 [==============================] - 1s 90ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.1519 - val_accuracy: 0.9423\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7afc1adb7430>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["X_test = X_test.astype(np.float32)  # Ensure that X_test is in float32\n","y_test = y_test.astype(np.int32)    # Ensure that y_test is in int32\n","\n","# Now you can evaluate the model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f'Test accuracy: {test_accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gX87lbsj0AAJ","executionInfo":{"status":"ok","timestamp":1697784203707,"user_tz":-330,"elapsed":2043,"user":{"displayName":"Mannan Junaid Abdul","userId":"12242438375363016538"}},"outputId":"799cc2ad-0382-465d-c67e-aae4c026cbf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 52ms/step - loss: 0.1251 - accuracy: 0.9519\n","Test accuracy: 0.9519230723381042\n"]}]},{"cell_type":"code","source":["# Specify the path where you want to save the model\n","model_save_path = '/content/drive/MyDrive/My_model.h5'  # Replace 'Your_Model_Name' with the desired name\n","\n","# Save the model\n","model.save(model_save_path)\n","\n","print(f\"Model saved to {model_save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeZHw3Kf05Uw","executionInfo":{"status":"ok","timestamp":1697784327435,"user_tz":-330,"elapsed":496,"user":{"displayName":"Mannan Junaid Abdul","userId":"12242438375363016538"}},"outputId":"32f899f1-516c-4766-9cba-9800a4175ef2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to /content/drive/MyDrive/My_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import librosa\n","import numpy as np\n","\n","# Constants for feature extraction\n","SAMPLE_RATE = 22050\n","DURATION = 4\n","MFCC_FEATURES = 13\n","\n","# Function to extract MFCC features from an audio clip\n","def extract_features(file_path, target_length):\n","    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n","    mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=MFCC_FEATURES)\n","\n","    # Pad or truncate to the target length\n","    if mfccs.shape[1] < target_length:\n","        mfccs = np.pad(mfccs, ((0, 0), (0, target_length - mfccs.shape[1])), mode='constant')\n","    elif mfccs.shape[1] > target_length:\n","        mfccs = mfccs[:, :target_length]\n","\n","    return mfccs\n","\n","# Path to your audio clip\n","audio_clip_path = '/content/drive/MyDrive/New Audio Folder/Pneumonia/Copy of P10_noise.wav'\n","\n","# Load the saved model\n","model_load_path = '/content/drive/MyDrive/My_model.h5'  # Specify the path to your saved model\n","loaded_model = tf.keras.models.load_model(model_load_path)\n","\n","# Extract MFCC features from the audio clip\n","target_length = 173  # Replace with your target length\n","audio_features = extract_features(audio_clip_path, target_length)\n","\n","# Reshape the audio features to match the model's input shape\n","audio_features = audio_features.reshape(1, MFCC_FEATURES, target_length, 1)\n","\n","# Make predictions\n","predictions = loaded_model.predict(audio_features)\n","\n","# The predictions will be a probability distribution over your classes. You can interpret the results.\n","# In this example, we'll assume a binary classification (Normal and Pneumonia).\n","if predictions[0][0] > predictions[0][1]:\n","    predicted_class = 'Normal'\n","else:\n","    predicted_class = 'Pneumonia'\n","\n","print(f'Predicted Class: {predicted_class}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIC51zvj1TbJ","executionInfo":{"status":"ok","timestamp":1697784552194,"user_tz":-330,"elapsed":3717,"user":{"displayName":"Mannan Junaid Abdul","userId":"12242438375363016538"}},"outputId":"bc7721ea-5e9a-4d81-d9ca-e3623b73153c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 167ms/step\n","Predicted Class: Pneumonia\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import librosa\n","import numpy as np\n","\n","# Constants for feature extraction\n","SAMPLE_RATE = 22050\n","DURATION = 4\n","MFCC_FEATURES = 13\n","\n","# Function to extract MFCC features from an audio clip\n","def extract_features(file_path, target_length):\n","    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n","    mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=MFCC_FEATURES)\n","\n","    # Pad or truncate to the target length\n","    if mfccs.shape[1] < target_length:\n","        mfccs = np.pad(mfccs, ((0, 0), (0, target_length - mfccs.shape[1])), mode='constant')\n","    elif mfccs.shape[1] > target_length:\n","        mfccs = mfccs[:, :target_length]\n","\n","    return mfccs\n","\n","# Path to your audio clip\n","audio_clip_path = '/content/drive/MyDrive/New Audio Folder/Normal/Copy of B11_pitch_shift.wav'\n","\n","# Load the saved model\n","model_load_path = '/content/drive/MyDrive/My_model.h5'  # Specify the path to your saved model\n","loaded_model = tf.keras.models.load_model(model_load_path)\n","\n","# Extract MFCC features from the audio clip\n","target_length = 173  # Replace with your target length\n","audio_features = extract_features(audio_clip_path, target_length)\n","\n","# Reshape the audio features to match the model's input shape\n","audio_features = audio_features.reshape(1, MFCC_FEATURES, target_length, 1)\n","\n","# Make predictions\n","predictions = loaded_model.predict(audio_features)\n","\n","# The predictions will be a probability distribution over your classes. You can interpret the results.\n","# In this example, we'll assume a binary classification (Normal and Pneumonia).\n","if predictions[0][0] > predictions[0][1]:\n","    predicted_class = 'Normal'\n","else:\n","    predicted_class = 'Pneumonia'\n","\n","print(f'Predicted Class: {predicted_class}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxud4fax2HNG","executionInfo":{"status":"ok","timestamp":1697808831203,"user_tz":-330,"elapsed":1455,"user":{"displayName":"Mannan Junaid Abdul","userId":"12242438375363016538"}},"outputId":"53250492-14f2-4091-9666-89790833b9a2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 101ms/step\n","Predicted Class: Normal\n"]}]}]}